{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "0f80d8c9",
      "metadata": {
        "id": "0f80d8c9"
      },
      "source": [
        "# Dataset Description"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a7ab437e",
      "metadata": {
        "id": "a7ab437e"
      },
      "source": [
        "## Satellite Images of Water Bodies\n",
        "A collection of water bodies images captured by the Sentinel-2 Satellite. Each image comes with a black and white mask where white represents water and black represents something else but water. The masks were generated by calculating the NWDI (Normalized Water Difference Index) which is frequently used to detect and measure vegetation in satellite images, but a greater threshold was used to detect water bodies.\n",
        "\n",
        "#### Sentinel-2 Satellite Images:\n",
        "Sentinel-2 is a satellite mission developed by the European Space Agency (ESA) as part of the Copernicus Programme. It is equipped with a multispectral imaging instrument that captures images of the Earth's surface across various spectral bands. These images are valuable for monitoring changes in the environment, including land cover, vegetation health, and water bodies.\n",
        "#### Black and White Masks:\n",
        "Each image in the  dataset is accompanied by a black and white mask. These masks serve as annotations or labels for the images, indicating the presence or absence of water bodies. In the masks, pixels that represent water are typically assigned a white color, while pixels representing non-water areas (such as land or built-up areas) are assigned a black color.\n",
        "#### Normalized Water Difference Index (NWDI):\n",
        "The NWDI is a spectral index commonly used in remote sensing to detect the presence of water in satellite images. It is calculated based on the differences in reflectance values between two specific spectral bands, typically near-infrared (NIR) and shortwave infrared (SWIR) bands. By comparing the reflectance values of these bands, the NWDI can highlight areas where water absorption features are present, allowing for the detection and delineation of water bodies in the images.\n",
        "#### Thresholding for Water Detection:\n",
        "In this dataset, a greater threshold than usual has been applied to the NWDI values to detect water bodies. This means that the threshold for classifying pixels as water or non-water has been set higher than the standard threshold used for vegetation detection. Adjusting the threshold allows for more accurate identification of water bodies while potentially reducing false positives or misclassifications.\n",
        "\n",
        "Link : https://www.kaggle.com/datasets/franciscoescobar/satellite-images-of-water-bodies/data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "zzR0rmwI1o7c",
      "metadata": {
        "id": "zzR0rmwI1o7c"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "75040590",
      "metadata": {
        "id": "75040590"
      },
      "source": [
        "### Import Important Libraries"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rasterio\n",
        "import rasterio"
      ],
      "metadata": {
        "id": "mUupDLrY3LLP"
      },
      "id": "mUupDLrY3LLP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "11b181a8",
      "metadata": {
        "id": "11b181a8"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from PIL import Image\n",
        "import random\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D\n",
        "from tensorflow.keras.layers import Input, concatenate\n",
        "from tensorflow.keras.models import Model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4fed9284",
      "metadata": {
        "id": "4fed9284"
      },
      "source": [
        "### Image Directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4761d25f",
      "metadata": {
        "id": "4761d25f"
      },
      "outputs": [],
      "source": [
        "image_dir = '/content/drive/MyDrive/APDS/Project/Satellite-Based-Water-Body-Segmentation-Using-CNNs/Water Bodies Dataset/Images'\n",
        "mask_dir = '/content/drive/MyDrive/APDS/Project/Satellite-Based-Water-Body-Segmentation-Using-CNNs/Water Bodies Dataset/Masks'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "38be2ac5",
      "metadata": {
        "id": "38be2ac5"
      },
      "outputs": [],
      "source": [
        "\n",
        "def list_all_image_ids():\n",
        "    image_ids = []\n",
        "    for filename in os.listdir(image_dir):\n",
        "        if filename.endswith('.jpg'):\n",
        "            image_id = filename.split('.')[0]\n",
        "            image_ids.append(image_id)\n",
        "    return image_ids\n",
        "\n",
        "def load_data(image_id):\n",
        "    image_path = f\"{image_dir}/{image_id}.jpg\"\n",
        "    image = Image.open(image_path).convert('RGB')\n",
        "    image = image.resize((64, 64))\n",
        "    image = np.array(image) / 255.0\n",
        "\n",
        "    mask_path = f\"{mask_dir}/{image_id}.jpg\"\n",
        "    mask = Image.open(mask_path).convert('L')\n",
        "    mask = mask.resize((64, 64))\n",
        "    mask = np.array(mask) / 255.0\n",
        "\n",
        "    return image, mask\n",
        "\n",
        "all_image_ids = list_all_image_ids()\n",
        "\n",
        "images = []\n",
        "masks = []\n",
        "\n",
        "for image_id in all_image_ids:\n",
        "    image, mask = load_data(image_id)\n",
        "    images.append(image)\n",
        "    masks.append(mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3bf02fb9",
      "metadata": {
        "id": "3bf02fb9"
      },
      "outputs": [],
      "source": [
        "len(images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "41cbb675",
      "metadata": {
        "id": "41cbb675"
      },
      "outputs": [],
      "source": [
        "len(masks)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9dc2fb89",
      "metadata": {
        "id": "9dc2fb89"
      },
      "source": [
        "### Plot Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "17f5dabf",
      "metadata": {
        "id": "17f5dabf"
      },
      "outputs": [],
      "source": [
        "num_random_images = 2\n",
        "random_image_ids = random.sample(all_image_ids, num_random_images)\n",
        "\n",
        "fig, axes = plt.subplots(num_random_images, 2, figsize=(12, 6*num_random_images))\n",
        "\n",
        "for i, image_id in enumerate(random_image_ids):\n",
        "    image, mask = load_data(image_id)\n",
        "    axes[i, 0].imshow(image)\n",
        "    axes[i, 0].set_title(f'Sentinel-2 Image ({image_id})')\n",
        "    axes[i, 1].imshow(mask, cmap='gray')\n",
        "    axes[i, 1].set_title(f'Mask (Water Bodies) ({image_id})')\n",
        "\n",
        "plt.tight_layout()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "feb8dcdc",
      "metadata": {
        "id": "feb8dcdc"
      },
      "outputs": [],
      "source": [
        "# Convert lists to NumPy arrays\n",
        "images = np.array(images, dtype=np.float32)\n",
        "masks = np.array(masks, dtype=np.float32)\n",
        "\n",
        "# Add a channel dimension to masks\n",
        "masks = masks[..., np.newaxis]\n",
        "\n",
        "# Verify the shapes\n",
        "print(f'Images shape: {images.shape}')\n",
        "print(f'Masks shape: {masks.shape}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "186119c1",
      "metadata": {
        "id": "186119c1"
      },
      "outputs": [],
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(images, masks, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c1c4acce",
      "metadata": {
        "id": "c1c4acce"
      },
      "outputs": [],
      "source": [
        "X_train.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cf59b28d",
      "metadata": {
        "id": "cf59b28d"
      },
      "source": [
        "This model is a simple convolutional neural network for image segmentation. It follows an encoder-decoder structure:\n",
        "\n",
        "#### Encoder:\n",
        "The first part consists of several convolutional layers followed by max pooling layers, which progressively reduce the spatial dimensions and increase the number of feature maps. This part extracts and compresses the features.\n",
        "\n",
        "#### Decoder:\n",
        "The second part consists of several upsampling layers followed by convolutional layers, which progressively increase the spatial dimensions back to the original size while refining the feature maps to produce the final segmentation mask."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9b09b2ba",
      "metadata": {
        "id": "9b09b2ba"
      },
      "outputs": [],
      "source": [
        "# Build a simple CNN model\n",
        "def build_model(input_shape):\n",
        "    inputs = Input(input_shape)\n",
        "    c1 = Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
        "    p1 = MaxPooling2D((2, 2))(c1)\n",
        "\n",
        "    c2 = Conv2D(64, (3, 3), activation='relu', padding='same')(p1)\n",
        "    p2 = MaxPooling2D((2, 2))(c2)\n",
        "\n",
        "    c3 = Conv2D(128, (3, 3), activation='relu', padding='same')(p2)\n",
        "    p3 = MaxPooling2D((2, 2))(c3)\n",
        "\n",
        "    c4 = Conv2D(256, (3, 3), activation='relu', padding='same')(p3)\n",
        "\n",
        "    u1 = UpSampling2D((2, 2))(c4)\n",
        "    c5 = Conv2D(128, (3, 3), activation='relu', padding='same')(u1)\n",
        "\n",
        "    u2 = UpSampling2D((2, 2))(c5)\n",
        "    c6 = Conv2D(64, (3, 3), activation='relu', padding='same')(u2)\n",
        "\n",
        "    u3 = UpSampling2D((2, 2))(c6)\n",
        "    c7 = Conv2D(32, (3, 3), activation='relu', padding='same')(u3)\n",
        "\n",
        "    outputs = Conv2D(1, (1, 1), activation='sigmoid')(c7)\n",
        "\n",
        "    model = Model(inputs=[inputs], outputs=[outputs])\n",
        "    return model\n",
        "\n",
        "input_shape = (64, 64, 3)\n",
        "model = build_model(input_shape)\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.summary\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, y_train, epochs=20, batch_size=16, validation_data=(X_val, y_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e4227a5f",
      "metadata": {
        "id": "e4227a5f"
      },
      "outputs": [],
      "source": [
        "# Evaluate the model on the validation data\n",
        "loss, accuracy = model.evaluate(X_val, y_val)\n",
        "print(f'Validation Loss: {loss:.4f}')\n",
        "print(f'Validation Accuracy: {accuracy:.4f}')\n",
        "\n",
        "# Predict masks for the validation data\n",
        "predicted_masks = model.predict(X_val)\n",
        "\n",
        "# Visualize original and predicted masks for a few samples\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "num_samples_to_visualize = 5\n",
        "indices_to_visualize = np.random.choice(len(X_val), num_samples_to_visualize, replace=False)\n",
        "\n",
        "for i in indices_to_visualize:\n",
        "    plt.figure(figsize=(15, 5))\n",
        "\n",
        "    # Original image\n",
        "    plt.subplot(1, 3, 1)\n",
        "    plt.imshow(X_val[i])\n",
        "    plt.title('Original Image')\n",
        "    plt.axis('off')\n",
        "\n",
        "    # Original mask\n",
        "    plt.subplot(1, 3, 2)\n",
        "    plt.imshow(np.squeeze(y_val[i]), cmap='gray')\n",
        "    plt.title('Original Mask')\n",
        "    plt.axis('off')\n",
        "\n",
        "    # Predicted mask\n",
        "    plt.subplot(1, 3, 3)\n",
        "    plt.imshow(np.squeeze(predicted_masks[i]), cmap='gray')\n",
        "    plt.title('Predicted Mask')\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8d3a1428",
      "metadata": {
        "id": "8d3a1428"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}